{"cells":[{"cell_type":"markdown","metadata":{"id":"BdX2B8o0gs94"},"source":["# Interacting with the Web\n","\n","The Internet is a gigantic data dump. There is all the social networking data from Facebook, Twitter, and so on. There is the news from all the traditional media sources plus Quartz, Vox, and so on. Then there is the data from organizations such as the World Bank, the Bureau of Labor Statistics, the US Census, or Chicago's Data Portal.  Finally, you have all your scientific data sources: the National Cancer Institute, the ProteinBank, or the Kyoto Gene and Genomes Encyclopedia.\n","\n","How can you use Python to access those sites and retrieve data for your research, your business, or your hobby?\n","\n","There are two main approaches to retrieve data from websources. The preferred approach is using **Application Program Interfaces** or APIs.  If an organization has decided to share its data, and they have the forethought and resources to do it, they will develop an API that will let you interact with their data.\n","\n","If the organization does not have the forethought or resources to create an API (or if they do not want to share their data), then you have to **crawl** their website and **scrape** their data.\n","\n","**Note:** Many organizations do not allow data scrapping from their website and so, there may not be any API to scrap the data from there and the traditional methods to use web-scrapping libraries also may not work.\n","\n","    In this notebook, we are going to see a demo of scrapping real-time data using a small API."]},{"cell_type":"markdown","metadata":{"id":"9_4wedVegs-C"},"source":["# Application Program Interfaces (APIs)\n","\n","\n","APIs simplify the process of obtaining specific information from a data source.  You do not have to worry about figuring out the **format** in which the information is stored, or **where** the information is stored.  All of those matter are handled seamlessly by the API.\n","\n","But convenience is not the only advantage of an API. APIs are also particular useful when:\n","\n","* You want a small piece of a much larger set of data. **Reddit comments** are one example. What if you want to just pull your own comments on Reddit? It doesn’t make much sense to download the entire Reddit database, then filter just your own comments.\n","    \n","* There is repeated computation involved. **Spotify has an API that can tell you the genre of a piece of music**. You could theoretically create your own classifier, and use it to categorize music, but you’ll never have as much data as Spotify does.\n","    \n","* The data is changing quickly. An example of this is **stock price data**. It doesn’t really make sense to regenerate a dataset and download it every minute – this will take a lot of bandwidth, and be pretty slow.\n","\n","* Many big companies have their own well-managed APIs using which we can scrap the data. Since the website and data structures may be different, it become very important that we look into the documentation of such APIs. For example, here is the link of Twitter API: https://developer.twitter.com/en/docs/twitter-api\n","    \n","    \n","    \n","### Making a request\n","\n","In order to learn how APIs work, we will first use the APIs developed to retrieve data on the **International Space Station (ISS)**.  The relevant APIs can be found at http://open-notify.org/.  We will first consider the API for retrieving the location (latitude and longitude) of the ISS (http://open-notify.org/Open-Notify-API/ISS-Location-Now/). The API is hosted at http://api.open-notify.org/iss-now.json.\n","\n","So, how do we make requests for information with this API?\n","\n","Like standard webpages, APIs are also hosted on web servers. When you type http://www.google.com in your browser’s address bar, your computer is actually asking the http://www.google.com server for a webpage, which it then returns it to your browser for display. That action is called a `request`. APIs work much the same way, except instead of your web browser asking for a webpage, your program asks for **data**. This data is usually returned in JSON format.\n","\n","There are many possible types of requests. The most common, and the one we will be using throughout this unit, is the `GET` request. A `GET` request simply accesses and downloads the webpage found at the URL you specified as an input.\n","\n","We will use the package [`requests`](http://docs.python-requests.org/en/latest/user/quickstart/) package to crawl (load) webpages and scrape (download) their contents."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"l6K2WIRAgs-I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752983069307,"user_tz":-480,"elapsed":408,"user":{"displayName":"Lyndon Lingbaoan","userId":"14699312238919118218"}},"outputId":"33ada4f7-7257-4719-e3c4-5d8f7798efdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["<Response [200]>\n","200\n"]}],"source":["import requests # This is a request library! it is really just a whole bunch of functions put together!\n","import json\n","\n","response = requests.get(\"http://api.open-notify.org/iss-now.json\")\n","print(response)\n","print(response.status_code)"]},{"cell_type":"markdown","metadata":{"id":"ohto_9aXgs-Q"},"source":["Methods from the `requests` package return `Response` objects. One of the most important properties of the response is its `status code`, which is printed by default but which we can also get explicitly.\n","\n","Here are some of the most common status codes you might encounter:\n","* 200, **OK**. Standard response for successful HTTP requests. The actual response will depend on the request method used.\n","* 301, **Moved Permanently**. The server is redirecting you to a different endpoint. This and all future requests should be directed to the given URL. This can happen when a company switches domain names, or an endpoint name is changed.\n","* 303, **See Other**. The response to the request can be found under another URI using a GET method. When received in response to a POST (or PUT/DELETE), the client should presume that the server has received the data and should issue a redirect with a separate GET message. Your web browser automatically fetches the new URL but web crawlers do not usually do this unless you specify it.\n","* 400, **Bad Request**. The server cannot or will not process the request due to an apparent client error (e.g., malformed request syntax, invalid request message framing, or deceptive request routing).\n","* 401, **Unauthorized**. Similar to `403 Forbidden`, but specifically for use when authentication is required and has failed or has not yet been provided. The response must include a WWW-Authenticate header field containing a challenge applicable to the requested resource.\n","* 403, **Forbidden**. The request was a valid request, but the server is refusing to respond to it. `403` error semantically means \"unauthorized\", i.e. the user does not have the necessary permissions for the resource.\n","* 404, **Not Found**. The requested resource could not be found but may be available in the future. Subsequent requests by the client are permissible.\n","* 500, **Internal Server Error**. A generic error message, given when an `unexpected` condition was encountered and no more specific message is suitable.\n","* 503, **Service Unavailable**. The server is currently unavailable (because it is overloaded or down for maintenance). Generally, this is a temporary state.\n","* 504, **Gateway Timeout**. The server was acting as a gateway or proxy and did not receive a timely response from the upstream server.[\n","\n","\n","\n","More codes: http://en.wikipedia.org/wiki/List_of_HTTP_status_codes"]},{"cell_type":"markdown","metadata":{"id":"8oHLtnW0gs-T"},"source":["The status code of our request was **200**. It means that all went well -- we successfully connected to the web address we wanted and downloaded its contents.\n","\n","But `status codes` are not the only methods available:"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cdjOtmOBgs-W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752983139312,"user_tz":-480,"elapsed":19,"user":{"displayName":"Lyndon Lingbaoan","userId":"14699312238919118218"}},"outputId":"50e20119-6fe2-496d-d5d0-7107ec5bc0a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["http://api.open-notify.org/iss-now.json\n"]}],"source":["print(response.url)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"E22djxREgs-f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752983142790,"user_tz":-480,"elapsed":11,"user":{"displayName":"Lyndon Lingbaoan","userId":"14699312238919118218"}},"outputId":"6a98ff41-2e7a-457a-9c6d-f07767bbe33c"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\"message\": \"success\", \"iss_position\": {\"longitude\": \"-107.9806\", \"latitude\": \"50.9244\"}, \"timestamp\": 1752983069}\n"]}],"source":["print(response.text)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Lf4dbNXPgdDw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1752983382607,"user_tz":-480,"elapsed":28333,"user":{"displayName":"Lyndon Lingbaoan","userId":"14699312238919118218"}},"outputId":"4f7ce6a2-5809-4498-8713-5d720f85e29f"},"outputs":[{"output_type":"stream","name":"stdout","text":["The ISS current position is 44.5657 of latitude and -83.1466 of longitude.\n","The ISS current position is 44.1640 of latitude and -82.2148 of longitude.\n","The ISS current position is 44.0011 of latitude and -81.8458 of longitude.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-7-1579851844.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://api.open-notify.org/iss-now.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(response.text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sleep for 5 secs/keep idle for 5 secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import requests #this is a request library! it is really just a whole bunch of functions put together!\n","import json\n","import time\n","\n","# Getting information in near real time\n","for i in range(1,100):\n","    response = requests.get(\"http://api.open-notify.org/iss-now.json\")\n","    #print(response.text)\n","    time.sleep(5) # sleep for 5 secs/keep idle for 5 secs\n","\n","    data = json.loads(response.text)\n","\n","    print( \"The ISS current position is {} of latitude and {} of longitude.\".format(\n","        data['iss_position']['latitude'],\n","        data['iss_position']['longitude']))\n","\n","# This cell will keep printing the ISS position every 5 seconds\n","# To stop it, interrupt the cell execution."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tqmuwmjYgs-6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752983293463,"user_tz":-480,"elapsed":13,"user":{"displayName":"Lyndon Lingbaoan","userId":"14699312238919118218"}},"outputId":"f9aad67c-88ad-4f9d-f5b2-8c0f23cbfda9"},"outputs":[{"output_type":"stream","name":"stdout","text":["The ISS current position is 47.3593 of latitude and -90.7995 of longitude.\n","The ISS current position is 47.3593 of latitude and -90.7995 of longitude.\n"]}],"source":["data = json.loads(response.text)\n","\n","print( \"The ISS current position is {} of latitude and {} of longitude.\".format(\n","        data['iss_position']['latitude'],\n","        data['iss_position']['longitude']))\n","\n","print( \"The ISS current position is \"+str(data['iss_position']['latitude'])+\" of latitude and \"+str(data['iss_position']['longitude'])+\" of longitude.\")"]},{"cell_type":"markdown","metadata":{"id":"G5S1WnrWXeDr"},"source":["Other way to scrap data from website is using web-scrapping libraries such as `beautifulsoup`, `scrappy` etc. In the additional reading, a notebook has been provided on web-scrapping through libraries for you to read."]}],"metadata":{"colab":{"provenance":[{"file_id":"1mm8abTraOCcnSRbS87WC5T_ON4D3bPpb","timestamp":1751463644096}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}